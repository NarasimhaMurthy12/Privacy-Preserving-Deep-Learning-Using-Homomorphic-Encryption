{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af6255ee",
   "metadata": {
    "id": "9DMr9rhddlYt",
    "papermill": {
     "duration": 0.00714,
     "end_time": "2025-04-01T15:30:30.816619",
     "exception": false,
     "start_time": "2025-04-01T15:30:30.809479",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Implementation of Deep Net with 1 hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0990bda3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T15:30:30.825824Z",
     "iopub.status.busy": "2025-04-01T15:30:30.825495Z",
     "iopub.status.idle": "2025-04-01T15:30:35.923329Z",
     "shell.execute_reply": "2025-04-01T15:30:35.922337Z"
    },
    "executionInfo": {
     "elapsed": 2835,
     "status": "ok",
     "timestamp": 1742798433014,
     "user": {
      "displayName": "Narasimha Murthy Panchangam",
      "userId": "15024520267351528624"
     },
     "user_tz": -330
    },
    "id": "Ygi2n_WBRT_q",
    "outputId": "b76a21e2-74f1-4760-88e9-2af760e6801d",
    "papermill": {
     "duration": 5.104061,
     "end_time": "2025-04-01T15:30:35.924867",
     "exception": false,
     "start_time": "2025-04-01T15:30:30.820806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tenseal\r\n",
      "  Downloading tenseal-0.3.16-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\r\n",
      "Downloading tenseal-0.3.16-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: tenseal\r\n",
      "Successfully installed tenseal-0.3.16\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tenseal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0b977b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T15:30:35.934591Z",
     "iopub.status.busy": "2025-04-01T15:30:35.934314Z",
     "iopub.status.idle": "2025-04-01T15:30:40.848498Z",
     "shell.execute_reply": "2025-04-01T15:30:40.847760Z"
    },
    "executionInfo": {
     "elapsed": 7696,
     "status": "ok",
     "timestamp": 1742798442252,
     "user": {
      "displayName": "Narasimha Murthy Panchangam",
      "userId": "15024520267351528624"
     },
     "user_tz": -330
    },
    "id": "1f47e986-014c-4ffd-94d1-631afde3099a",
    "papermill": {
     "duration": 4.920693,
     "end_time": "2025-04-01T15:30:40.850094",
     "exception": false,
     "start_time": "2025-04-01T15:30:35.929401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import tenseal as ts\n",
    "import pandas as pd\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "# those are optional and are not necessary for training\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93be0fe5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T15:30:40.859902Z",
     "iopub.status.busy": "2025-04-01T15:30:40.859462Z",
     "iopub.status.idle": "2025-04-01T15:30:40.990638Z",
     "shell.execute_reply": "2025-04-01T15:30:40.989261Z"
    },
    "executionInfo": {
     "elapsed": 404,
     "status": "ok",
     "timestamp": 1742798461263,
     "user": {
      "displayName": "Narasimha Murthy Panchangam",
      "userId": "15024520267351528624"
     },
     "user_tz": -330
    },
    "id": "b5c04e07-ee8c-49e8-a8ab-b30b06efeba7",
    "outputId": "4852cd9a-6e06-4d6c-c09e-240dd3a9044e",
    "papermill": {
     "duration": 0.137512,
     "end_time": "2025-04-01T15:30:40.992275",
     "exception": false,
     "start_time": "2025-04-01T15:30:40.854763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      male  age  cigsPerDay  prevalentStroke  prevalentHyp  totChol  sysBP  \\\n",
      "0        1   39         0.0                0             0    195.0  106.0   \n",
      "1        0   46         0.0                0             0    250.0  121.0   \n",
      "2        1   48        20.0                0             0    245.0  127.5   \n",
      "3        0   61        30.0                0             1    225.0  150.0   \n",
      "4        0   46        23.0                0             0    285.0  130.0   \n",
      "...    ...  ...         ...              ...           ...      ...    ...   \n",
      "4231     1   58         0.0                0             1    187.0  141.0   \n",
      "4232     1   68         0.0                0             1    176.0  168.0   \n",
      "4233     1   50         1.0                0             1    313.0  179.0   \n",
      "4234     1   51        43.0                0             0    207.0  126.5   \n",
      "4237     0   52         0.0                0             0    269.0  133.5   \n",
      "\n",
      "        BMI  heartRate  glucose  TenYearCHD  \n",
      "0     26.97       80.0     77.0           0  \n",
      "1     28.73       95.0     76.0           0  \n",
      "2     25.34       75.0     70.0           0  \n",
      "3     28.58       65.0    103.0           1  \n",
      "4     23.10       85.0     85.0           0  \n",
      "...     ...        ...      ...         ...  \n",
      "4231  24.96       80.0     81.0           0  \n",
      "4232  23.14       60.0     79.0           1  \n",
      "4233  25.97       66.0     86.0           1  \n",
      "4234  19.71       65.0     68.0           0  \n",
      "4237  21.47       80.0    107.0           0  \n",
      "\n",
      "[3656 rows x 11 columns]\n",
      "############# Data summary #############\n",
      "x_train has shape: torch.Size([780, 11])\n",
      "y_train has shape: torch.Size([780, 1])\n",
      "x_test has shape: torch.Size([334, 11])\n",
      "y_test has shape: torch.Size([334, 1])\n",
      "#######################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-cbb9a12a9c89>:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data = grouped.apply(lambda x: x.sample(grouped.size().min(), random_state=73).reset_index(drop=True))\n"
     ]
    }
   ],
   "source": [
    "torch.random.manual_seed(73)\n",
    "random.seed(73)\n",
    "\n",
    "\n",
    "def split_train_test(x, y, test_ratio=0.3):\n",
    "    idxs = [i for i in range(len(x))]\n",
    "    random.shuffle(idxs)\n",
    "    # delimiter between test and train data\n",
    "    delim = int(len(x) * test_ratio)\n",
    "    test_idxs, train_idxs = idxs[:delim], idxs[delim:]\n",
    "    return x[train_idxs], y[train_idxs], x[test_idxs], y[test_idxs]\n",
    "\n",
    "\n",
    "def heart_disease_data():\n",
    "    data = pd.read_csv(\"/kaggle/input/trydataset/framingham.csv\")\n",
    "    # drop rows with missing values\n",
    "    data = data.dropna()\n",
    "    # drop some features\n",
    "    data = data.drop(columns=[\"education\", \"currentSmoker\", \"BPMeds\", \"diabetes\", \"diaBP\"])\n",
    "    print(data)\n",
    "    # balance data\n",
    "    grouped = data.groupby('TenYearCHD')\n",
    "    data = grouped.apply(lambda x: x.sample(grouped.size().min(), random_state=73).reset_index(drop=True))\n",
    "    # extract labels\n",
    "    y = torch.tensor(data[\"TenYearCHD\"].values).float().unsqueeze(1)\n",
    "    #data = data.drop(\"TenYearCHD\",'columns')\n",
    "    # standardize data\n",
    "    data = (data - data.mean()) / data.std()\n",
    "    x = torch.tensor(data.values).float()\n",
    "    return split_train_test(x, y)\n",
    "\n",
    "\n",
    "def random_data(m=1024, n=2):\n",
    "    # data separable by the line `y = x`\n",
    "    x_train = torch.randn(m, n)\n",
    "    x_test = torch.randn(m // 2, n)\n",
    "    y_train = (x_train[:, 0] >= x_train[:, 1]).float().unsqueeze(0).t()\n",
    "    y_test = (x_test[:, 0] >= x_test[:, 1]).float().unsqueeze(0).t()\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "# You can use whatever data you want without modification to the tutorial\n",
    "# x_train, y_train, x_test, y_test = random_data()\n",
    "x_train, y_train, x_test, y_test = heart_disease_data()\n",
    "\n",
    "print(\"############# Data summary #############\")\n",
    "print(f\"x_train has shape: {x_train.shape}\")\n",
    "print(f\"y_train has shape: {y_train.shape}\")\n",
    "print(f\"x_test has shape: {x_test.shape}\")\n",
    "print(f\"y_test has shape: {y_test.shape}\")\n",
    "print(\"#######################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89bfbd77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T15:30:41.001634Z",
     "iopub.status.busy": "2025-04-01T15:30:41.001360Z",
     "iopub.status.idle": "2025-04-01T15:30:42.248897Z",
     "shell.execute_reply": "2025-04-01T15:30:42.247693Z"
    },
    "executionInfo": {
     "elapsed": 1347,
     "status": "ok",
     "timestamp": 1742798466748,
     "user": {
      "displayName": "Narasimha Murthy Panchangam",
      "userId": "15024520267351528624"
     },
     "user_tz": -330
    },
    "id": "7d29335d-0550-47cc-a59f-ac72fe2ea0e3",
    "papermill": {
     "duration": 1.254533,
     "end_time": "2025-04-01T15:30:42.250941",
     "exception": false,
     "start_time": "2025-04-01T15:30:40.996408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "poly_mod_degree = 8192\n",
    "coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 21, 40]\n",
    "# create TenSEALContext\n",
    "ctx_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "ctx_training.global_scale = 2 ** 21\n",
    "ctx_training.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc57df0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T15:30:42.260620Z",
     "iopub.status.busy": "2025-04-01T15:30:42.260285Z",
     "iopub.status.idle": "2025-04-01T15:30:42.263809Z",
     "shell.execute_reply": "2025-04-01T15:30:42.262874Z"
    },
    "executionInfo": {
     "elapsed": 27042,
     "status": "ok",
     "timestamp": 1742798845589,
     "user": {
      "displayName": "Narasimha Murthy Panchangam",
      "userId": "15024520267351528624"
     },
     "user_tz": -330
    },
    "id": "fca037ed-0491-4249-8032-e567ff666951",
    "outputId": "1cc5433b-df31-4bba-8614-9d9a4864e8ec",
    "papermill": {
     "duration": 0.009904,
     "end_time": "2025-04-01T15:30:42.265527",
     "exception": false,
     "start_time": "2025-04-01T15:30:42.255623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#t_start = time()\n",
    "#enc_x_train = ts.ckks_tensor(ctx_training, x_train[0:300])\n",
    "#enc_y_train = ts.ckks_tensor(ctx_training, y_train[0:300])\n",
    "#t_end = time()\n",
    "#print(f\"Encryption of the training_set took {int(t_end - t_start)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1d3b6b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T15:30:42.274322Z",
     "iopub.status.busy": "2025-04-01T15:30:42.274023Z",
     "iopub.status.idle": "2025-04-01T15:30:42.286233Z",
     "shell.execute_reply": "2025-04-01T15:30:42.285616Z"
    },
    "executionInfo": {
     "elapsed": 402,
     "status": "ok",
     "timestamp": 1742798869375,
     "user": {
      "displayName": "Narasimha Murthy Panchangam",
      "userId": "15024520267351528624"
     },
     "user_tz": -330
    },
    "id": "LocrA1zn57Ep",
    "papermill": {
     "duration": 0.018068,
     "end_time": "2025-04-01T15:30:42.287449",
     "exception": false,
     "start_time": "2025-04-01T15:30:42.269381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncryptedDL1layer() :\n",
    "  def __init__(self) -> None:\n",
    "      self.weight1=np.random.rand(11,3)*0.01\n",
    "      self.bias1=np.random.rand(3)*0.01\n",
    "      self.weight2=np.random.rand(3, 1)*0.01\n",
    "      self.bias2=np.random.rand(1)*0.01\n",
    "      self.dw1=0\n",
    "      self.db1=0\n",
    "      self.dw2=0\n",
    "      self.db2=0\n",
    "  def bootstrapping(enc,ctx_training) :\n",
    "    return ts.ckks_tensor(ctx_training,enc.decrypt())\n",
    "  def softplus(enc_x):\n",
    "    return enc_x.polyval([np.log(2),0.5,(1/8), 0,-(1/192)])\n",
    "  def softplus_derv(enc_x):\n",
    "    return enc_x.polyval([0.5,0.25,0,-(1/48)])\n",
    "  def forward(self,enc_x_train,ctx_training) :\n",
    "    z11=enc_x_train.mm(self.weight1)\n",
    "    z1=z11.add(self.bias1)\n",
    "    a1=EncryptedDL1layer.softplus(z1)\n",
    "    y=EncryptedDL1layer.bootstrapping(a1,ctx_training)\n",
    "    z21=y.mm(self.weight2)\n",
    "    z2=z21.add(self.bias2)\n",
    "    a2=EncryptedDL1layer.softplus(z2)\n",
    "    return a2,z2,a1,z1\n",
    "  def backward(self,a2,z2,a1,z1,enc_y_train,ctx_training) :\n",
    "    #calculating the output at the layer 2\n",
    "    error=a2-enc_y_train\n",
    "    der=EncryptedDL1layer.softplus_derv(z2)\n",
    "    #finding delta2\n",
    "    delta2=error.mul(der)\n",
    "    #using bootstrapping\n",
    "    delta2=EncryptedDL1layer.bootstrapping(delta2,ctx_training)\n",
    "    #finding delta1\n",
    "    del1=delta2.mm(self.weight2.transpose())\n",
    "    del1=EncryptedDL1layer.bootstrapping(del1,ctx_training)\n",
    "    #finding der1\n",
    "    der1=EncryptedDL1layer.softplus_derv(z1)\n",
    "    #using bootstrapping\n",
    "    der1=EncryptedDL1layer.bootstrapping(der1,ctx_training)\n",
    "    #finding delta1\n",
    "    delta1=del1.mul(der1)\n",
    "    #finding the gradients\n",
    "    #for weight2 and bias2\n",
    "    self.dw2=a1.transpose().mm(delta2)\n",
    "    self.db2=delta2.sum()\n",
    "    #for weight1 and bias1\n",
    "    self.dw1=enc_x_train.transpose().mm(delta1)\n",
    "    self.db1=delta1.sum()\n",
    "  def update_params(self):\n",
    "    self.weight2=self.weight2-0.01*self.dw2\n",
    "    self.bias2=self.bias2-0.01*self.db2\n",
    "    self.weight1=self.weight1-0.01*self.dw1\n",
    "    self.bias1=self.bias1-0.01*self.db1\n",
    "  def encrypt(self, context):\n",
    "    self.weight1 = ts.ckks_tensor(context, self.weight1)\n",
    "    self.bias1 = ts.ckks_tensor(context, self.bias1)\n",
    "    self.weight2 = ts.ckks_tensor(context, self.weight2)\n",
    "    self.bias2 = ts.ckks_tensor(context, self.bias2)\n",
    "  def decrypt(self):\n",
    "    self.weight1 = self.weight1.decrypt()\n",
    "    self.bias1 = self.bias1.decrypt()\n",
    "    self.weight2 = self.weight2.decrypt()\n",
    "    self.bias2 = self.bias2.decrypt()\n",
    "  def accuracy(self,x_test,y_test):\n",
    "    #self.decrypt()\n",
    "    w1 = torch.tensor(self.weight1)\n",
    "    b1 = torch.tensor(self.bias1)\n",
    "    out1 = torch.softplus(x_test.matmul(w1) + b1).reshape(-1, 1)\n",
    "    w2 = torch.tensor(self.weight2)\n",
    "    b2 = torch.tensor(self.bias2)\n",
    "    out2 = torch.softplus(out1.matmul(w2) + b2).reshape(-1, 1)\n",
    "    correct = torch.abs(y_test - out2) < 0.5\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e11b5d5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T15:30:42.296018Z",
     "iopub.status.busy": "2025-04-01T15:30:42.295780Z",
     "iopub.status.idle": "2025-04-01T17:42:28.128684Z",
     "shell.execute_reply": "2025-04-01T17:42:28.127587Z"
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "error",
     "timestamp": 1742798872001,
     "user": {
      "displayName": "Narasimha Murthy Panchangam",
      "userId": "15024520267351528624"
     },
     "user_tz": -330
    },
    "id": "vj7f2Rt3BTsJ",
    "outputId": "8a0f6c19-8d47-4bb6-c90a-2509b6cf5d03",
    "papermill": {
     "duration": 7905.838941,
     "end_time": "2025-04-01T17:42:28.130137",
     "exception": false,
     "start_time": "2025-04-01T15:30:42.291196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  0\n",
      "Batch :  0.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.49766516685486\n",
      "Batch :  1.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  57.017350912094116\n",
      "Batch :  2.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  57.00425934791565\n",
      "Batch :  3.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  57.12011504173279\n",
      "Batch :  4.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  56.68119168281555\n",
      "Batch :  5.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  55.926328897476196\n",
      "Batch :  6.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  56.55456781387329\n",
      "Batch :  7.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  56.71977186203003\n",
      "Batch :  8.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  57.029115200042725\n",
      "Batch :  9.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  55.67157530784607\n",
      "Batch :  10.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  57.568557262420654\n",
      "Batch :  11.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.01389145851135\n",
      "Batch :  12.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  57.09696984291077\n",
      "Loss at epoch  0 tensor(0.6627)\n",
      "Accuracy at epoch  0 tensor(0.9667)\n",
      "Epoch :  1\n",
      "Batch :  0.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  56.46757483482361\n",
      "Batch :  1.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  57.59615778923035\n",
      "Batch :  2.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  57.54576063156128\n",
      "Batch :  3.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  57.261883020401\n",
      "Batch :  4.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  56.60316276550293\n",
      "Batch :  5.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  54.610082387924194\n",
      "Batch :  6.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  54.89419198036194\n",
      "Batch :  7.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  55.96983456611633\n",
      "Batch :  8.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  57.89843702316284\n",
      "Batch :  9.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  57.62488651275635\n",
      "Batch :  10.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  56.5326886177063\n",
      "Batch :  11.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  57.83190846443176\n",
      "Batch :  12.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  58.492286920547485\n",
      "Loss at epoch  1 tensor(0.5544)\n",
      "Accuracy at epoch  1 tensor(1.)\n",
      "Epoch :  2\n",
      "Batch :  0.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.67556691169739\n",
      "Batch :  1.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  61.423343658447266\n",
      "Batch :  2.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.80833148956299\n",
      "Batch :  3.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.27259349822998\n",
      "Batch :  4.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.103673458099365\n",
      "Batch :  5.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.87950158119202\n",
      "Batch :  6.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  58.426053285598755\n",
      "Batch :  7.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  58.51701521873474\n",
      "Batch :  8.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.127480268478394\n",
      "Batch :  9.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.52391314506531\n",
      "Batch :  10.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.01651430130005\n",
      "Batch :  11.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.0178918838501\n",
      "Batch :  12.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.12157678604126\n",
      "Loss at epoch  2 tensor(0.5104)\n",
      "Accuracy at epoch  2 tensor(1.)\n",
      "Epoch :  3\n",
      "Batch :  0.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  58.36624598503113\n",
      "Batch :  1.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.83312106132507\n",
      "Batch :  2.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  61.238765239715576\n",
      "Batch :  3.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.86826753616333\n",
      "Batch :  4.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  61.69829988479614\n",
      "Batch :  5.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  61.5932354927063\n",
      "Batch :  6.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  62.36354470252991\n",
      "Batch :  7.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  61.307496786117554\n",
      "Batch :  8.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.65527629852295\n",
      "Batch :  9.0\n",
      "Encryption of the training_set took 4 seconds\n",
      "Time taken for this batch :  61.375447273254395\n",
      "Batch :  10.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.968621492385864\n",
      "Batch :  11.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  61.2987916469574\n",
      "Batch :  12.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  61.89237976074219\n",
      "Loss at epoch  3 tensor(0.4998)\n",
      "Accuracy at epoch  3 tensor(1.)\n",
      "Epoch :  4\n",
      "Batch :  0.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.883028745651245\n",
      "Batch :  1.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.52424240112305\n",
      "Batch :  2.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.18704581260681\n",
      "Batch :  3.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.133185386657715\n",
      "Batch :  4.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.925509214401245\n",
      "Batch :  5.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.70947051048279\n",
      "Batch :  6.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.49388647079468\n",
      "Batch :  7.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  57.27645778656006\n",
      "Batch :  8.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  58.731722593307495\n",
      "Batch :  9.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.82624793052673\n",
      "Batch :  10.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.59643316268921\n",
      "Batch :  11.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  58.68275833129883\n",
      "Batch :  12.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  57.93574571609497\n",
      "Loss at epoch  4 tensor(0.4976)\n",
      "Accuracy at epoch  4 tensor(1.)\n",
      "Epoch :  5\n",
      "Batch :  0.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  58.61094069480896\n",
      "Batch :  1.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  58.00310015678406\n",
      "Batch :  2.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  58.73897647857666\n",
      "Batch :  3.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  58.47498917579651\n",
      "Batch :  4.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  58.5405056476593\n",
      "Batch :  5.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.2710120677948\n",
      "Batch :  6.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  61.56764483451843\n",
      "Batch :  7.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  61.36599946022034\n",
      "Batch :  8.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.38159799575806\n",
      "Batch :  9.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.87425708770752\n",
      "Batch :  10.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  62.26928472518921\n",
      "Batch :  11.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  62.59460186958313\n",
      "Batch :  12.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  63.29291391372681\n",
      "Loss at epoch  5 tensor(0.4972)\n",
      "Accuracy at epoch  5 tensor(1.)\n",
      "Epoch :  6\n",
      "Batch :  0.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  62.02784252166748\n",
      "Batch :  1.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  62.25807809829712\n",
      "Batch :  2.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  61.91996884346008\n",
      "Batch :  3.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.066983699798584\n",
      "Batch :  4.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.390841484069824\n",
      "Batch :  5.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.74833607673645\n",
      "Batch :  6.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.71865153312683\n",
      "Batch :  7.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.07499384880066\n",
      "Batch :  8.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.2742817401886\n",
      "Batch :  9.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.327587604522705\n",
      "Batch :  10.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.13461637496948\n",
      "Batch :  11.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.20232367515564\n",
      "Batch :  12.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.2885377407074\n",
      "Loss at epoch  6 tensor(0.4968)\n",
      "Accuracy at epoch  6 tensor(1.)\n",
      "Epoch :  7\n",
      "Batch :  0.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.23406362533569\n",
      "Batch :  1.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.76124358177185\n",
      "Batch :  2.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.63217759132385\n",
      "Batch :  3.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.02243900299072\n",
      "Batch :  4.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.0339515209198\n",
      "Batch :  5.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  58.87985110282898\n",
      "Batch :  6.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.58280348777771\n",
      "Batch :  7.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.56568884849548\n",
      "Batch :  8.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  62.94177269935608\n",
      "Batch :  9.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  62.712868452072144\n",
      "Batch :  10.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  63.4594669342041\n",
      "Batch :  11.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  63.38618087768555\n",
      "Batch :  12.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  62.724271059036255\n",
      "Loss at epoch  7 tensor(0.4969)\n",
      "Accuracy at epoch  7 tensor(1.)\n",
      "Epoch :  8\n",
      "Batch :  0.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  63.08446931838989\n",
      "Batch :  1.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  63.36166334152222\n",
      "Batch :  2.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  62.03653144836426\n",
      "Batch :  3.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.78729271888733\n",
      "Batch :  4.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.257712841033936\n",
      "Batch :  5.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.48115110397339\n",
      "Batch :  6.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.225027084350586\n",
      "Batch :  7.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.76962232589722\n",
      "Batch :  8.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.06065630912781\n",
      "Batch :  9.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.581570863723755\n",
      "Batch :  10.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.36202597618103\n",
      "Batch :  11.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  61.69031858444214\n",
      "Batch :  12.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  61.118563652038574\n",
      "Loss at epoch  8 tensor(0.4969)\n",
      "Accuracy at epoch  8 tensor(1.)\n",
      "Epoch :  9\n",
      "Batch :  0.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.21709656715393\n",
      "Batch :  1.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.555423736572266\n",
      "Batch :  2.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.41903328895569\n",
      "Batch :  3.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.06238889694214\n",
      "Batch :  4.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  58.43467831611633\n",
      "Batch :  5.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  58.40068864822388\n",
      "Batch :  6.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.23916697502136\n",
      "Batch :  7.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.40901589393616\n",
      "Batch :  8.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.20425581932068\n",
      "Batch :  9.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.35959815979004\n",
      "Batch :  10.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  60.70574164390564\n",
      "Batch :  11.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.78523397445679\n",
      "Batch :  12.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  59.53663921356201\n",
      "Loss at epoch  9 tensor(0.4969)\n",
      "Accuracy at epoch  9 tensor(1.)\n",
      "\n",
      "Average time per epoch: 59 seconds\n",
      "Final weight1  [[-0.013609604115393914, 0.010344926961475643, -0.007960315869075234], [-0.04310218471352089, 0.023964137036081044, -0.0087528102667286], [-0.016076740476688774, -0.0039648556423203495, 0.012342479942763584], [-0.009962841804998337, -2.819645905915316e-05, 0.005470288282370828], [-0.02797678471441815, 0.016218184669422035, -0.0037929341113277313], [-0.016087221414124567, 0.0021412195370750617, 0.003288010418293667], [-0.019199490871018417, 0.009224719434780882, -0.003922978723759683], [-0.005954518929480677, -0.0002269045397508902, -0.00039369717586756187], [0.001657224490209072, 0.0030684140154324914, -0.004549998202996821], [-0.016621905227570524, 0.010374839545108224, -0.0009620801404592752], [-0.6575146779946114, -1.0258300152542286, -0.8934989117745867]]\n",
      "Final bias 1 [-0.049905667223396774, 0.012940738762468372, -0.007773192958992628]\n",
      "Final weight 2 [[-0.291980826830259], [-0.8284805733689471], [-0.6280077953771276]]\n",
      "Final bias 2 [0.9664023207457385]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "eelr = EncryptedDL1layer()\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"Epoch : \",epoch)\n",
    "    times = []\n",
    "    t_start = time()\n",
    "    for i in range(0,780,60):\n",
    "        print(\"Batch : \",i/60)\n",
    "        t_start = time()\n",
    "        enc_x_train = ts.ckks_tensor(ctx_training, x_train[i:i+60])\n",
    "        enc_y_train = ts.ckks_tensor(ctx_training, y_train[i:i+60])\n",
    "        t_end = time()\n",
    "        print(f\"Encryption of the training_set took {int(t_end - t_start)} seconds\")\n",
    "        eelr.encrypt(ctx_training)\n",
    "        a2,z2,a1,z1 = eelr.forward(enc_x_train,ctx_training)\n",
    "        eelr.backward(a2,z2,a1,z1,enc_y_train,ctx_training)\n",
    "        eelr.update_params()\n",
    "        t_end = time()\n",
    "        eelr.decrypt()\n",
    "        print(\"Time taken for this batch : \",t_end - t_start)\n",
    "    times.append(t_end - t_start)\n",
    "    a2,z2,a1,z1 = eelr.forward(enc_x_train,ctx_training)\n",
    "    data=torch.tensor(a2.decrypt().tolist())\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "    loss = loss_fn(data, y_train[i:i+60])\n",
    "    print(\"Loss at epoch \",epoch,loss.data)\n",
    "    out=torch.tensor(enc_y_train.sub(a2).decrypt().tolist())\n",
    "    correct=torch.abs(out)<0.5\n",
    "    print(\"Accuracy at epoch \",epoch,correct.float().mean())\n",
    "print(f\"\\nAverage time per epoch: {int(sum(times) / len(times))} seconds\")\n",
    "print(\"Final weight1 \",eelr.weight1.tolist())\n",
    "print(\"Final bias 1\",eelr.bias1.tolist())\n",
    "print(\"Final weight 2\",eelr.weight2.tolist())\n",
    "print(\"Final bias 2\",eelr.bias2.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04539652",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T17:42:28.163760Z",
     "iopub.status.busy": "2025-04-01T17:42:28.163411Z",
     "iopub.status.idle": "2025-04-01T17:42:41.622939Z",
     "shell.execute_reply": "2025-04-01T17:42:41.622112Z"
    },
    "executionInfo": {
     "elapsed": 92271,
     "status": "ok",
     "timestamp": 1742745772755,
     "user": {
      "displayName": "Narasimha Murthy",
      "userId": "00427524539684510099"
     },
     "user_tz": -330
    },
    "id": "KLgUVLDRjFUR",
    "outputId": "0516727f-29d4-430d-df09-8d40fa237b83",
    "papermill": {
     "duration": 13.478147,
     "end_time": "2025-04-01T17:42:41.624903",
     "exception": false,
     "start_time": "2025-04-01T17:42:28.146756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#eelr.encrypt(ctx_training)\n",
    "j,k,l,r=eelr.forward(enc_x_train,ctx_training)\n",
    "#enc_y_train.sub(j).decrypt().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f37c2605",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T17:42:41.660877Z",
     "iopub.status.busy": "2025-04-01T17:42:41.660536Z",
     "iopub.status.idle": "2025-04-01T17:42:41.810798Z",
     "shell.execute_reply": "2025-04-01T17:42:41.809979Z"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1742746346136,
     "user": {
      "displayName": "Narasimha Murthy",
      "userId": "00427524539684510099"
     },
     "user_tz": -330
    },
    "id": "_UaJ3vhlvLCX",
    "outputId": "8854fc07-8857-4b2b-b1b1-07b7a048fa53",
    "papermill": {
     "duration": 0.169266,
     "end_time": "2025-04-01T17:42:41.812088",
     "exception": false,
     "start_time": "2025-04-01T17:42:41.642822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "out=torch.tensor(enc_y_train.sub(j).decrypt().tolist())\n",
    "correct=torch.abs(out)<0.5\n",
    "print(correct.float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e2ce2c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T17:42:41.847270Z",
     "iopub.status.busy": "2025-04-01T17:42:41.846921Z",
     "iopub.status.idle": "2025-04-01T17:43:03.193517Z",
     "shell.execute_reply": "2025-04-01T17:43:03.192403Z"
    },
    "id": "WiNUecEKxti0",
    "papermill": {
     "duration": 21.366296,
     "end_time": "2025-04-01T17:43:03.195335",
     "exception": false,
     "start_time": "2025-04-01T17:42:41.829039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc_x_test = ts.ckks_tensor(ctx_training, x_test)\n",
    "enc_y_test = ts.ckks_tensor(ctx_training, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80803557",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T17:43:03.240590Z",
     "iopub.status.busy": "2025-04-01T17:43:03.240131Z",
     "iopub.status.idle": "2025-04-01T17:44:25.838710Z",
     "shell.execute_reply": "2025-04-01T17:44:25.837781Z"
    },
    "papermill": {
     "duration": 82.618628,
     "end_time": "2025-04-01T17:44:25.840196",
     "exception": false,
     "start_time": "2025-04-01T17:43:03.221568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "m,n,j,k=eelr.forward(enc_x_test,ctx_training)\n",
    "out=torch.tensor(enc_y_test.sub(m).decrypt().tolist())\n",
    "correct=torch.abs(out)<0.5\n",
    "print(correct.float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec70bb33",
   "metadata": {
    "papermill": {
     "duration": 0.015711,
     "end_time": "2025-04-01T17:44:25.871630",
     "exception": false,
     "start_time": "2025-04-01T17:44:25.855919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6961199,
     "sourceId": 11156928,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7023869,
     "sourceId": 11242015,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8041.084281,
   "end_time": "2025-04-01T17:44:29.490513",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-01T15:30:28.406232",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
