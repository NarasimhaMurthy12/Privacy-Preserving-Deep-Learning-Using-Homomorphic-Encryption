{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a978467b",
   "metadata": {
    "id": "9DMr9rhddlYt",
    "papermill": {
     "duration": 0.004595,
     "end_time": "2025-04-01T15:40:20.030823",
     "exception": false,
     "start_time": "2025-04-01T15:40:20.026228",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Implementation of Deep Net with 1 hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beb65fd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T15:40:20.040256Z",
     "iopub.status.busy": "2025-04-01T15:40:20.039791Z",
     "iopub.status.idle": "2025-04-01T15:40:26.966590Z",
     "shell.execute_reply": "2025-04-01T15:40:26.965244Z"
    },
    "executionInfo": {
     "elapsed": 2835,
     "status": "ok",
     "timestamp": 1742798433014,
     "user": {
      "displayName": "Narasimha Murthy Panchangam",
      "userId": "15024520267351528624"
     },
     "user_tz": -330
    },
    "id": "Ygi2n_WBRT_q",
    "outputId": "b76a21e2-74f1-4760-88e9-2af760e6801d",
    "papermill": {
     "duration": 6.933418,
     "end_time": "2025-04-01T15:40:26.968377",
     "exception": false,
     "start_time": "2025-04-01T15:40:20.034959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tenseal\r\n",
      "  Downloading tenseal-0.3.16-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\r\n",
      "Downloading tenseal-0.3.16-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: tenseal\r\n",
      "Successfully installed tenseal-0.3.16\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tenseal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e01b7f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T15:40:26.978835Z",
     "iopub.status.busy": "2025-04-01T15:40:26.978487Z",
     "iopub.status.idle": "2025-04-01T15:40:32.785563Z",
     "shell.execute_reply": "2025-04-01T15:40:32.784503Z"
    },
    "executionInfo": {
     "elapsed": 7696,
     "status": "ok",
     "timestamp": 1742798442252,
     "user": {
      "displayName": "Narasimha Murthy Panchangam",
      "userId": "15024520267351528624"
     },
     "user_tz": -330
    },
    "id": "1f47e986-014c-4ffd-94d1-631afde3099a",
    "papermill": {
     "duration": 5.814461,
     "end_time": "2025-04-01T15:40:32.787572",
     "exception": false,
     "start_time": "2025-04-01T15:40:26.973111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import tenseal as ts\n",
    "import pandas as pd\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "# those are optional and are not necessary for training\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc813490",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T15:40:32.798943Z",
     "iopub.status.busy": "2025-04-01T15:40:32.798457Z",
     "iopub.status.idle": "2025-04-01T15:40:32.947083Z",
     "shell.execute_reply": "2025-04-01T15:40:32.946013Z"
    },
    "executionInfo": {
     "elapsed": 404,
     "status": "ok",
     "timestamp": 1742798461263,
     "user": {
      "displayName": "Narasimha Murthy Panchangam",
      "userId": "15024520267351528624"
     },
     "user_tz": -330
    },
    "id": "b5c04e07-ee8c-49e8-a8ab-b30b06efeba7",
    "outputId": "4852cd9a-6e06-4d6c-c09e-240dd3a9044e",
    "papermill": {
     "duration": 0.156227,
     "end_time": "2025-04-01T15:40:32.948684",
     "exception": false,
     "start_time": "2025-04-01T15:40:32.792457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Data summary #############\n",
      "x_train has shape: torch.Size([780, 10])\n",
      "y_train has shape: torch.Size([780, 1])\n",
      "x_test has shape: torch.Size([334, 10])\n",
      "y_test has shape: torch.Size([334, 1])\n",
      "#######################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-9c1daa9f64ab>:22: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data = grouped.apply(lambda x: x.sample(grouped.size().min(), random_state=73).reset_index(drop=True))\n"
     ]
    }
   ],
   "source": [
    "torch.random.manual_seed(73)\n",
    "random.seed(73)\n",
    "\n",
    "\n",
    "def split_train_test(x, y, test_ratio=0.3):\n",
    "    idxs = [i for i in range(len(x))]\n",
    "    random.shuffle(idxs)\n",
    "    # delimiter between test and train data\n",
    "    delim = int(len(x) * test_ratio)\n",
    "    test_idxs, train_idxs = idxs[:delim], idxs[delim:]\n",
    "    return x[train_idxs], y[train_idxs], x[test_idxs], y[test_idxs]\n",
    "\n",
    "\n",
    "def heart_disease_data():\n",
    "    data = pd.read_csv(\"/kaggle/input/trydataset1/framingham.csv\")\n",
    "    # drop rows with missing values\n",
    "    data = data.dropna()\n",
    "    # drop some features\n",
    "    data = data.drop(columns=[\"education\", \"currentSmoker\", \"BPMeds\", \"diabetes\", \"diaBP\", \"BMI\"])\n",
    "    # balance data\n",
    "    grouped = data.groupby('TenYearCHD')\n",
    "    data = grouped.apply(lambda x: x.sample(grouped.size().min(), random_state=73).reset_index(drop=True))\n",
    "    # extract labels\n",
    "    y = torch.tensor(data[\"TenYearCHD\"].values).float().unsqueeze(1)\n",
    "    #data = data.drop(\"TenYearCHD\",'columns')\n",
    "    # standardize data\n",
    "    data = (data - data.mean()) / data.std()\n",
    "    x = torch.tensor(data.values).float()\n",
    "    return split_train_test(x, y)\n",
    "\n",
    "\n",
    "def random_data(m=1024, n=2):\n",
    "    # data separable by the line `y = x`\n",
    "    x_train = torch.randn(m, n)\n",
    "    x_test = torch.randn(m // 2, n)\n",
    "    y_train = (x_train[:, 0] >= x_train[:, 1]).float().unsqueeze(0).t()\n",
    "    y_test = (x_test[:, 0] >= x_test[:, 1]).float().unsqueeze(0).t()\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "# You can use whatever data you want without modification to the tutorial\n",
    "# x_train, y_train, x_test, y_test = random_data()\n",
    "x_train, y_train, x_test, y_test = heart_disease_data()\n",
    "\n",
    "print(\"############# Data summary #############\")\n",
    "print(f\"x_train has shape: {x_train.shape}\")\n",
    "print(f\"y_train has shape: {y_train.shape}\")\n",
    "print(f\"x_test has shape: {x_test.shape}\")\n",
    "print(f\"y_test has shape: {y_test.shape}\")\n",
    "print(\"#######################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3434ddaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T15:40:32.959333Z",
     "iopub.status.busy": "2025-04-01T15:40:32.958898Z",
     "iopub.status.idle": "2025-04-01T15:40:34.306393Z",
     "shell.execute_reply": "2025-04-01T15:40:34.305226Z"
    },
    "executionInfo": {
     "elapsed": 1347,
     "status": "ok",
     "timestamp": 1742798466748,
     "user": {
      "displayName": "Narasimha Murthy Panchangam",
      "userId": "15024520267351528624"
     },
     "user_tz": -330
    },
    "id": "7d29335d-0550-47cc-a59f-ac72fe2ea0e3",
    "papermill": {
     "duration": 1.354653,
     "end_time": "2025-04-01T15:40:34.308144",
     "exception": false,
     "start_time": "2025-04-01T15:40:32.953491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "poly_mod_degree = 8192\n",
    "coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 21, 40]\n",
    "# create TenSEALContext\n",
    "ctx_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "ctx_training.global_scale = 2 ** 21\n",
    "ctx_training.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68eeab03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T15:40:34.318901Z",
     "iopub.status.busy": "2025-04-01T15:40:34.318536Z",
     "iopub.status.idle": "2025-04-01T15:40:34.322524Z",
     "shell.execute_reply": "2025-04-01T15:40:34.321463Z"
    },
    "executionInfo": {
     "elapsed": 27042,
     "status": "ok",
     "timestamp": 1742798845589,
     "user": {
      "displayName": "Narasimha Murthy Panchangam",
      "userId": "15024520267351528624"
     },
     "user_tz": -330
    },
    "id": "fca037ed-0491-4249-8032-e567ff666951",
    "outputId": "1cc5433b-df31-4bba-8614-9d9a4864e8ec",
    "papermill": {
     "duration": 0.011163,
     "end_time": "2025-04-01T15:40:34.324135",
     "exception": false,
     "start_time": "2025-04-01T15:40:34.312972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#t_start = time()\n",
    "#enc_x_train = ts.ckks_tensor(ctx_training, x_train[0:300])\n",
    "#enc_y_train = ts.ckks_tensor(ctx_training, y_train[0:300])\n",
    "#t_end = time()\n",
    "#print(f\"Encryption of the training_set took {int(t_end - t_start)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61aa687e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T15:40:34.334823Z",
     "iopub.status.busy": "2025-04-01T15:40:34.334505Z",
     "iopub.status.idle": "2025-04-01T15:40:34.347999Z",
     "shell.execute_reply": "2025-04-01T15:40:34.346961Z"
    },
    "executionInfo": {
     "elapsed": 402,
     "status": "ok",
     "timestamp": 1742798869375,
     "user": {
      "displayName": "Narasimha Murthy Panchangam",
      "userId": "15024520267351528624"
     },
     "user_tz": -330
    },
    "id": "LocrA1zn57Ep",
    "papermill": {
     "duration": 0.02091,
     "end_time": "2025-04-01T15:40:34.349790",
     "exception": false,
     "start_time": "2025-04-01T15:40:34.328880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncryptedDL1layer() :\n",
    "  def __init__(self) -> None:\n",
    "      self.weight1=np.random.rand(10,3)*0.01\n",
    "      self.bias1=np.random.rand(3)*0.01\n",
    "      self.weight2=np.random.rand(3, 1)*0.01\n",
    "      self.bias2=np.random.rand(1)*0.01\n",
    "      self.dw1=0\n",
    "      self.db1=0\n",
    "      self.dw2=0\n",
    "      self.db2=0\n",
    "  def bootstrapping(enc,ctx_training) :\n",
    "    return ts.ckks_tensor(ctx_training,enc.decrypt())\n",
    "  def sigmoid(enc_x):\n",
    "    return enc_x.polyval([0.5, 0.197, 0, -0.004])\n",
    "  def sigmoid_derv(enc_x):\n",
    "    return enc_x.polyval([0.197,0,-0.012,0])\n",
    "  def forward(self,enc_x_train,ctx_training) :\n",
    "    z11=enc_x_train.mm(self.weight1)\n",
    "    z1=z11.add(self.bias1)\n",
    "    a1=EncryptedDL1layer.sigmoid(z1)\n",
    "    y=EncryptedDL1layer.bootstrapping(a1,ctx_training)\n",
    "    z21=y.mm(self.weight2)\n",
    "    z2=z21.add(self.bias2)\n",
    "    a2=EncryptedDL1layer.sigmoid(z2)\n",
    "    return a2,z2,a1,z1\n",
    "  def backward(self,a2,z2,a1,z1,enc_y_train,ctx_training) :\n",
    "    #calculating the output at the layer 2\n",
    "    error=a2-enc_y_train\n",
    "    der=EncryptedDL1layer.sigmoid_derv(z2)\n",
    "    #finding delta2\n",
    "    delta2=error.mul(der)\n",
    "    #using bootstrapping\n",
    "    delta2=EncryptedDL1layer.bootstrapping(delta2,ctx_training)\n",
    "    #finding delta1\n",
    "    del1=delta2.mm(self.weight2.transpose())\n",
    "    del1=EncryptedDL1layer.bootstrapping(del1,ctx_training)\n",
    "    #finding der1\n",
    "    der1=EncryptedDL1layer.sigmoid_derv(z1)\n",
    "    #using bootstrapping\n",
    "    der1=EncryptedDL1layer.bootstrapping(der1,ctx_training)\n",
    "    #finding delta1\n",
    "    delta1=del1.mul(der1)\n",
    "    #finding the gradients\n",
    "    #for weight2 and bias2\n",
    "    self.dw2=a1.transpose().mm(delta2)\n",
    "    self.db2=delta2.sum()\n",
    "    #for weight1 and bias1\n",
    "    self.dw1=enc_x_train.transpose().mm(delta1)\n",
    "    self.db1=delta1.sum()\n",
    "  def update_params(self):\n",
    "    self.weight2=self.weight2-0.1*self.dw2\n",
    "    self.bias2=self.bias2-0.1*self.db2\n",
    "    self.weight1=self.weight1-0.1*self.dw1\n",
    "    self.bias1=self.bias1-0.1*self.db1\n",
    "  def encrypt(self, context):\n",
    "    self.weight1 = ts.ckks_tensor(context, self.weight1)\n",
    "    self.bias1 = ts.ckks_tensor(context, self.bias1)\n",
    "    self.weight2 = ts.ckks_tensor(context, self.weight2)\n",
    "    self.bias2 = ts.ckks_tensor(context, self.bias2)\n",
    "  def decrypt(self):\n",
    "    self.weight1 = self.weight1.decrypt()\n",
    "    self.bias1 = self.bias1.decrypt()\n",
    "    self.weight2 = self.weight2.decrypt()\n",
    "    self.bias2 = self.bias2.decrypt()\n",
    "  def accuracy(self,x_test,y_test):\n",
    "    #self.decrypt()\n",
    "    w1 = torch.tensor(self.weight1)\n",
    "    b1 = torch.tensor(self.bias1)\n",
    "    out1 = torch.sigmoid(x_test.matmul(w1) + b1).reshape(-1, 1)\n",
    "    w2 = torch.tensor(self.weight2)\n",
    "    b2 = torch.tensor(self.bias2)\n",
    "    out2 = torch.sigmoid(out1.matmul(w2) + b2).reshape(-1, 1)\n",
    "    correct = torch.abs(y_test - out2) < 0.5\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4773eec8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T15:40:34.360620Z",
     "iopub.status.busy": "2025-04-01T15:40:34.360277Z",
     "iopub.status.idle": "2025-04-01T17:45:18.985623Z",
     "shell.execute_reply": "2025-04-01T17:45:18.984265Z"
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "error",
     "timestamp": 1742798872001,
     "user": {
      "displayName": "Narasimha Murthy Panchangam",
      "userId": "15024520267351528624"
     },
     "user_tz": -330
    },
    "id": "vj7f2Rt3BTsJ",
    "outputId": "8a0f6c19-8d47-4bb6-c90a-2509b6cf5d03",
    "papermill": {
     "duration": 7484.632982,
     "end_time": "2025-04-01T17:45:18.987603",
     "exception": false,
     "start_time": "2025-04-01T15:40:34.354621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  0.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  55.62975859642029\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  1.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.76258373260498\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  2.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.08171248435974\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  3.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.288294553756714\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  4.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.97127032279968\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  5.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.727197885513306\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  6.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.411006450653076\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  7.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.31367635726929\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  8.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.73260688781738\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  9.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.11370539665222\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  10.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.36855745315552\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  11.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.96943545341492\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  12.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.425567388534546\n",
      "Loss at epoch  0 tensor(0.7094)\n",
      "Accuracy at epoch  0 tensor(0.5167)\n",
      "Epoch :  1\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  0.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.34989833831787\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  1.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.4938805103302\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  2.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.88964915275574\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  3.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.79764175415039\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  4.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.206509590148926\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  5.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.97184348106384\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  6.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.393277406692505\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  7.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.98320436477661\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  8.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.51295280456543\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  9.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.425405502319336\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  10.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.94872736930847\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  11.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.72195816040039\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  12.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.993794441223145\n",
      "Loss at epoch  1 tensor(0.5376)\n",
      "Accuracy at epoch  1 tensor(1.)\n",
      "Epoch :  2\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  0.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.708868741989136\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  1.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.25638699531555\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  2.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.63821840286255\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  3.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.30810070037842\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  4.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.73294711112976\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  5.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.40488076210022\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  6.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.63997769355774\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  7.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.718586444854736\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  8.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.67635369300842\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  9.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.19623684883118\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  10.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.175822496414185\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  11.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.559643507003784\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  12.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.812386989593506\n",
      "Loss at epoch  2 tensor(0.5082)\n",
      "Accuracy at epoch  2 tensor(1.)\n",
      "Epoch :  3\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  0.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.037721395492554\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  1.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.42426371574402\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  2.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.66300868988037\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  3.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.856069803237915\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  4.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.752021074295044\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  5.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.33294081687927\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  6.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.81673789024353\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  7.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.20696830749512\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  8.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.16905760765076\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  9.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.13464593887329\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  10.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.90101623535156\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  11.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.575074195861816\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  12.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.88917684555054\n",
      "Loss at epoch  3 tensor(0.5020)\n",
      "Accuracy at epoch  3 tensor(1.)\n",
      "Epoch :  4\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  0.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.675464153289795\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  1.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.020402908325195\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  2.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.56560444831848\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  3.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.823784589767456\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  4.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.476322174072266\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  5.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.72212839126587\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  6.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.48996138572693\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  7.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.89358472824097\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  8.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.52914214134216\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  9.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.00196170806885\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  10.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.8431396484375\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  11.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.233532190322876\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  12.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.71660757064819\n",
      "Loss at epoch  4 tensor(0.4993)\n",
      "Accuracy at epoch  4 tensor(1.)\n",
      "Epoch :  5\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  0.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.21629738807678\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  1.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.64564299583435\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  2.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.00968146324158\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  3.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.5513973236084\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  4.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.261733531951904\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  5.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.11139750480652\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  6.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.66269326210022\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  7.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.60815405845642\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  8.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.640302658081055\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  9.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.829137563705444\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  10.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.411670207977295\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  11.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.8093683719635\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  12.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.48416590690613\n",
      "Loss at epoch  5 tensor(0.4984)\n",
      "Accuracy at epoch  5 tensor(1.)\n",
      "Epoch :  6\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  0.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.222490549087524\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  1.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.84545922279358\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  2.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.04648971557617\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  3.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.14508628845215\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  4.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  54.240090131759644\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  5.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.750123262405396\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  6.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.83615279197693\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  7.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.553802251815796\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  8.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.28152585029602\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  9.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.08341598510742\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  10.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.676676750183105\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  11.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.49569582939148\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  12.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.6530396938324\n",
      "Loss at epoch  6 tensor(0.4974)\n",
      "Accuracy at epoch  6 tensor(1.)\n",
      "Epoch :  7\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  0.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.670920610427856\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  1.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  54.10177826881409\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  2.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.964046239852905\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  3.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.568195819854736\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  4.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.669519662857056\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  5.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.42826843261719\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  6.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.52185273170471\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  7.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.76104140281677\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  8.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.95859217643738\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  9.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.50503993034363\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  10.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.938812255859375\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  11.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.42724609375\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  12.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.47570252418518\n",
      "Loss at epoch  7 tensor(0.4977)\n",
      "Accuracy at epoch  7 tensor(1.)\n",
      "Epoch :  8\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  0.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.59038519859314\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  1.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.28128933906555\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  2.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.57636308670044\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  3.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.64765000343323\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  4.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.97469735145569\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  5.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.69727158546448\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  6.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.17025923728943\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  7.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.426371812820435\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  8.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.38020944595337\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  9.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.95855259895325\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  10.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.65908718109131\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  11.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.633477449417114\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  12.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.67122197151184\n",
      "Loss at epoch  8 tensor(0.4971)\n",
      "Accuracy at epoch  8 tensor(1.)\n",
      "Epoch :  9\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  0.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.97096395492554\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  1.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.68043041229248\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  2.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.52745985984802\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  3.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.69275736808777\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  4.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.00460696220398\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  5.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.79633951187134\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  6.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.41378140449524\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  7.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.32822370529175\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  8.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.70360803604126\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  9.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.48475360870361\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  10.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  53.54597306251526\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  11.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.954668283462524\n",
      "Encryption of the training_set took 3 seconds\n",
      "Batch :  12.0\n",
      "\n",
      "\n",
      "Time taken for this batch :  52.5546600818634\n",
      "Loss at epoch  9 tensor(0.4973)\n",
      "Accuracy at epoch  9 tensor(1.)\n",
      "\n",
      "Average time per epoch: 53 seconds\n",
      "Final weight1  [[0.05446255580769033, 0.04216710770364737, 0.0028213114674261516], [0.07777319947447733, 0.042340327840843454, 0.02496577340159221], [0.07114944674561877, 0.027296762975502677, 0.04179669889220388], [0.08760901977143176, 0.017413148584887933, 0.09488241737830434], [0.05999166914459433, 0.05294183254639355, -0.024785248804701097], [0.03504805636416354, 0.011882534062617486, -0.006486372890855595], [0.08498156977806125, 0.05574201429717466, 0.0059027166558534554], [0.010752277371671304, 0.01634747365810342, -0.015903759229652193], [0.06560076949982942, 0.05008227158192813, 0.018516512320322264], [1.6697767129542465, -0.3326364549867138, 2.4974350562372805]]\n",
      "Final bias 1 [-0.29298261880872634, 0.097443868868422, -0.23109976006348915]\n",
      "Final weight 2 [[1.5381565090337619], [-1.047552945378356], [3.1926638507193275]]\n",
      "Final bias 2 [-1.999265373691194]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "eelr = EncryptedDL1layer()\n",
    "times = []\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"Epoch : \",epoch)\n",
    "    for i in range(0,780,60):\n",
    "        t_start = time()\n",
    "        enc_x_train = ts.ckks_tensor(ctx_training, x_train[i:i+60])\n",
    "        enc_y_train = ts.ckks_tensor(ctx_training, y_train[i:i+60])\n",
    "        t_end = time()\n",
    "        print(f\"Encryption of the training_set took {int(t_end - t_start)} seconds\")\n",
    "        print(\"Batch : \",i/60)\n",
    "        eelr.encrypt(ctx_training)\n",
    "        t_start = time()\n",
    "        a2,z2,a1,z1 = eelr.forward(enc_x_train,ctx_training)\n",
    "        eelr.backward(a2,z2,a1,z1,enc_y_train,ctx_training)\n",
    "        eelr.update_params()\n",
    "        t_end = time()    \n",
    "        eelr.decrypt()\n",
    "        print(\"\\n\")\n",
    "        print(\"Time taken for this batch : \",t_end - t_start)\n",
    "    times.append(t_end - t_start)\n",
    "    a2,z2,a1,z1 = eelr.forward(enc_x_train,ctx_training)\n",
    "    data=torch.tensor(a2.decrypt().tolist())\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "    loss = loss_fn(data, y_train[i:i+60])\n",
    "    print(\"Loss at epoch \",epoch,loss.data)\n",
    "    out=torch.tensor(enc_y_train.sub(a2).decrypt().tolist())\n",
    "    correct=torch.abs(out)<0.5\n",
    "    print(\"Accuracy at epoch \",epoch,correct.float().mean())\n",
    "print(f\"\\nAverage time per epoch: {int(sum(times) / len(times))} seconds\")\n",
    "print(\"Final weight1 \",eelr.weight1.tolist())\n",
    "print(\"Final bias 1\",eelr.bias1.tolist())\n",
    "print(\"Final weight 2\",eelr.weight2.tolist())\n",
    "print(\"Final bias 2\",eelr.bias2.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9297f48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T17:45:19.025574Z",
     "iopub.status.busy": "2025-04-01T17:45:19.025246Z",
     "iopub.status.idle": "2025-04-01T17:45:19.031617Z",
     "shell.execute_reply": "2025-04-01T17:45:19.030500Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1742742509928,
     "user": {
      "displayName": "Narasimha Murthy",
      "userId": "00427524539684510099"
     },
     "user_tz": -330
    },
    "id": "5G7lXa-Qd5Dn",
    "outputId": "b4fe4b74-19d9-43fd-9e78-626740813bef",
    "papermill": {
     "duration": 0.026946,
     "end_time": "2025-04-01T17:45:19.033203",
     "exception": false,
     "start_time": "2025-04-01T17:45:19.006257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05446255580769033, 0.04216710770364737, 0.0028213114674261516], [0.07777319947447733, 0.042340327840843454, 0.02496577340159221], [0.07114944674561877, 0.027296762975502677, 0.04179669889220388], [0.08760901977143176, 0.017413148584887933, 0.09488241737830434], [0.05999166914459433, 0.05294183254639355, -0.024785248804701097], [0.03504805636416354, 0.011882534062617486, -0.006486372890855595], [0.08498156977806125, 0.05574201429717466, 0.0059027166558534554], [0.010752277371671304, 0.01634747365810342, -0.015903759229652193], [0.06560076949982942, 0.05008227158192813, 0.018516512320322264], [1.6697767129542465, -0.3326364549867138, 2.4974350562372805]]\n",
      "[-0.29298261880872634, 0.097443868868422, -0.23109976006348915]\n",
      "[[1.5381565090337619], [-1.047552945378356], [3.1926638507193275]]\n",
      "[-1.999265373691194]\n"
     ]
    }
   ],
   "source": [
    "print(eelr.weight1.tolist())\n",
    "print(eelr.bias1.tolist())\n",
    "print(eelr.weight2.tolist())\n",
    "print(eelr.bias2.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcce6fcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T17:45:19.070850Z",
     "iopub.status.busy": "2025-04-01T17:45:19.070493Z",
     "iopub.status.idle": "2025-04-01T17:45:31.324270Z",
     "shell.execute_reply": "2025-04-01T17:45:31.323217Z"
    },
    "executionInfo": {
     "elapsed": 92271,
     "status": "ok",
     "timestamp": 1742745772755,
     "user": {
      "displayName": "Narasimha Murthy",
      "userId": "00427524539684510099"
     },
     "user_tz": -330
    },
    "id": "KLgUVLDRjFUR",
    "outputId": "0516727f-29d4-430d-df09-8d40fa237b83",
    "papermill": {
     "duration": 12.274516,
     "end_time": "2025-04-01T17:45:31.326108",
     "exception": false,
     "start_time": "2025-04-01T17:45:19.051592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#eelr.encrypt(ctx_training)\n",
    "j,k,l,r=eelr.forward(enc_x_train,ctx_training)\n",
    "#enc_y_train.sub(j).decrypt().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71c26cdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T17:45:31.363279Z",
     "iopub.status.busy": "2025-04-01T17:45:31.362815Z",
     "iopub.status.idle": "2025-04-01T17:45:31.559196Z",
     "shell.execute_reply": "2025-04-01T17:45:31.558141Z"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1742746346136,
     "user": {
      "displayName": "Narasimha Murthy",
      "userId": "00427524539684510099"
     },
     "user_tz": -330
    },
    "id": "_UaJ3vhlvLCX",
    "outputId": "8854fc07-8857-4b2b-b1b1-07b7a048fa53",
    "papermill": {
     "duration": 0.216725,
     "end_time": "2025-04-01T17:45:31.561109",
     "exception": false,
     "start_time": "2025-04-01T17:45:31.344384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "out=torch.tensor(enc_y_train.sub(j).decrypt().tolist())\n",
    "correct=torch.abs(out)<0.5\n",
    "print(correct.float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b05e72bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T17:45:31.599203Z",
     "iopub.status.busy": "2025-04-01T17:45:31.598834Z",
     "iopub.status.idle": "2025-04-01T17:45:52.675427Z",
     "shell.execute_reply": "2025-04-01T17:45:52.674277Z"
    },
    "id": "WiNUecEKxti0",
    "papermill": {
     "duration": 21.097434,
     "end_time": "2025-04-01T17:45:52.677204",
     "exception": false,
     "start_time": "2025-04-01T17:45:31.579770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc_x_test = ts.ckks_tensor(ctx_training, x_test)\n",
    "enc_y_test = ts.ckks_tensor(ctx_training, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5139d724",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T17:45:52.715795Z",
     "iopub.status.busy": "2025-04-01T17:45:52.715488Z",
     "iopub.status.idle": "2025-04-01T17:47:13.812469Z",
     "shell.execute_reply": "2025-04-01T17:47:13.811343Z"
    },
    "papermill": {
     "duration": 81.136206,
     "end_time": "2025-04-01T17:47:13.831889",
     "exception": false,
     "start_time": "2025-04-01T17:45:52.695683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "m,n,j,k=eelr.forward(enc_x_test,ctx_training)\n",
    "out=torch.tensor(enc_y_test.sub(m).decrypt().tolist())\n",
    "correct=torch.abs(out)<0.5\n",
    "print(correct.float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cad5529",
   "metadata": {
    "papermill": {
     "duration": 0.018268,
     "end_time": "2025-04-01T17:47:13.868533",
     "exception": false,
     "start_time": "2025-04-01T17:47:13.850265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6961199,
     "sourceId": 11156928,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7620.052216,
   "end_time": "2025-04-01T17:47:17.206524",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-01T15:40:17.154308",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
