{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07ac828f",
   "metadata": {
    "id": "9DMr9rhddlYt",
    "papermill": {
     "duration": 0.00457,
     "end_time": "2025-04-01T15:25:00.497202",
     "exception": false,
     "start_time": "2025-04-01T15:25:00.492632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Implementation of Deep Net with 1 hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45c2a018",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T15:25:00.507422Z",
     "iopub.status.busy": "2025-04-01T15:25:00.506941Z",
     "iopub.status.idle": "2025-04-01T15:25:08.383843Z",
     "shell.execute_reply": "2025-04-01T15:25:08.382260Z"
    },
    "executionInfo": {
     "elapsed": 2835,
     "status": "ok",
     "timestamp": 1742798433014,
     "user": {
      "displayName": "Narasimha Murthy Panchangam",
      "userId": "15024520267351528624"
     },
     "user_tz": -330
    },
    "id": "Ygi2n_WBRT_q",
    "outputId": "b76a21e2-74f1-4760-88e9-2af760e6801d",
    "papermill": {
     "duration": 7.88411,
     "end_time": "2025-04-01T15:25:08.385858",
     "exception": false,
     "start_time": "2025-04-01T15:25:00.501748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tenseal\r\n",
      "  Downloading tenseal-0.3.16-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\r\n",
      "Downloading tenseal-0.3.16-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: tenseal\r\n",
      "Successfully installed tenseal-0.3.16\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tenseal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b7101cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T15:25:08.396696Z",
     "iopub.status.busy": "2025-04-01T15:25:08.396267Z",
     "iopub.status.idle": "2025-04-01T15:25:15.011372Z",
     "shell.execute_reply": "2025-04-01T15:25:15.010142Z"
    },
    "executionInfo": {
     "elapsed": 7696,
     "status": "ok",
     "timestamp": 1742798442252,
     "user": {
      "displayName": "Narasimha Murthy Panchangam",
      "userId": "15024520267351528624"
     },
     "user_tz": -330
    },
    "id": "1f47e986-014c-4ffd-94d1-631afde3099a",
    "papermill": {
     "duration": 6.623051,
     "end_time": "2025-04-01T15:25:15.013760",
     "exception": false,
     "start_time": "2025-04-01T15:25:08.390709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import tenseal as ts\n",
    "import pandas as pd\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "# those are optional and are not necessary for training\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b59691a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T15:25:15.024435Z",
     "iopub.status.busy": "2025-04-01T15:25:15.023941Z",
     "iopub.status.idle": "2025-04-01T15:25:15.209408Z",
     "shell.execute_reply": "2025-04-01T15:25:15.207355Z"
    },
    "executionInfo": {
     "elapsed": 404,
     "status": "ok",
     "timestamp": 1742798461263,
     "user": {
      "displayName": "Narasimha Murthy Panchangam",
      "userId": "15024520267351528624"
     },
     "user_tz": -330
    },
    "id": "b5c04e07-ee8c-49e8-a8ab-b30b06efeba7",
    "outputId": "4852cd9a-6e06-4d6c-c09e-240dd3a9044e",
    "papermill": {
     "duration": 0.193078,
     "end_time": "2025-04-01T15:25:15.211468",
     "exception": false,
     "start_time": "2025-04-01T15:25:15.018390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      male  age  cigsPerDay  prevalentStroke  prevalentHyp  totChol  sysBP  \\\n",
      "0        1   39         0.0                0             0    195.0  106.0   \n",
      "1        0   46         0.0                0             0    250.0  121.0   \n",
      "2        1   48        20.0                0             0    245.0  127.5   \n",
      "3        0   61        30.0                0             1    225.0  150.0   \n",
      "4        0   46        23.0                0             0    285.0  130.0   \n",
      "...    ...  ...         ...              ...           ...      ...    ...   \n",
      "4231     1   58         0.0                0             1    187.0  141.0   \n",
      "4232     1   68         0.0                0             1    176.0  168.0   \n",
      "4233     1   50         1.0                0             1    313.0  179.0   \n",
      "4234     1   51        43.0                0             0    207.0  126.5   \n",
      "4237     0   52         0.0                0             0    269.0  133.5   \n",
      "\n",
      "        BMI  heartRate  glucose  TenYearCHD  \n",
      "0     26.97       80.0     77.0           0  \n",
      "1     28.73       95.0     76.0           0  \n",
      "2     25.34       75.0     70.0           0  \n",
      "3     28.58       65.0    103.0           1  \n",
      "4     23.10       85.0     85.0           0  \n",
      "...     ...        ...      ...         ...  \n",
      "4231  24.96       80.0     81.0           0  \n",
      "4232  23.14       60.0     79.0           1  \n",
      "4233  25.97       66.0     86.0           1  \n",
      "4234  19.71       65.0     68.0           0  \n",
      "4237  21.47       80.0    107.0           0  \n",
      "\n",
      "[3656 rows x 11 columns]\n",
      "############# Data summary #############\n",
      "x_train has shape: torch.Size([780, 11])\n",
      "y_train has shape: torch.Size([780, 1])\n",
      "x_test has shape: torch.Size([334, 11])\n",
      "y_test has shape: torch.Size([334, 1])\n",
      "#######################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-cbb9a12a9c89>:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data = grouped.apply(lambda x: x.sample(grouped.size().min(), random_state=73).reset_index(drop=True))\n"
     ]
    }
   ],
   "source": [
    "torch.random.manual_seed(73)\n",
    "random.seed(73)\n",
    "\n",
    "\n",
    "def split_train_test(x, y, test_ratio=0.3):\n",
    "    idxs = [i for i in range(len(x))]\n",
    "    random.shuffle(idxs)\n",
    "    # delimiter between test and train data\n",
    "    delim = int(len(x) * test_ratio)\n",
    "    test_idxs, train_idxs = idxs[:delim], idxs[delim:]\n",
    "    return x[train_idxs], y[train_idxs], x[test_idxs], y[test_idxs]\n",
    "\n",
    "\n",
    "def heart_disease_data():\n",
    "    data = pd.read_csv(\"/kaggle/input/trydataset/framingham.csv\")\n",
    "    # drop rows with missing values\n",
    "    data = data.dropna()\n",
    "    # drop some features\n",
    "    data = data.drop(columns=[\"education\", \"currentSmoker\", \"BPMeds\", \"diabetes\", \"diaBP\"])\n",
    "    print(data)\n",
    "    # balance data\n",
    "    grouped = data.groupby('TenYearCHD')\n",
    "    data = grouped.apply(lambda x: x.sample(grouped.size().min(), random_state=73).reset_index(drop=True))\n",
    "    # extract labels\n",
    "    y = torch.tensor(data[\"TenYearCHD\"].values).float().unsqueeze(1)\n",
    "    #data = data.drop(\"TenYearCHD\",'columns')\n",
    "    # standardize data\n",
    "    data = (data - data.mean()) / data.std()\n",
    "    x = torch.tensor(data.values).float()\n",
    "    return split_train_test(x, y)\n",
    "\n",
    "\n",
    "def random_data(m=1024, n=2):\n",
    "    # data separable by the line `y = x`\n",
    "    x_train = torch.randn(m, n)\n",
    "    x_test = torch.randn(m // 2, n)\n",
    "    y_train = (x_train[:, 0] >= x_train[:, 1]).float().unsqueeze(0).t()\n",
    "    y_test = (x_test[:, 0] >= x_test[:, 1]).float().unsqueeze(0).t()\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "# You can use whatever data you want without modification to the tutorial\n",
    "# x_train, y_train, x_test, y_test = random_data()\n",
    "x_train, y_train, x_test, y_test = heart_disease_data()\n",
    "\n",
    "print(\"############# Data summary #############\")\n",
    "print(f\"x_train has shape: {x_train.shape}\")\n",
    "print(f\"y_train has shape: {y_train.shape}\")\n",
    "print(f\"x_test has shape: {x_test.shape}\")\n",
    "print(f\"y_test has shape: {y_test.shape}\")\n",
    "print(\"#######################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a958261",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T15:25:15.223249Z",
     "iopub.status.busy": "2025-04-01T15:25:15.222904Z",
     "iopub.status.idle": "2025-04-01T15:25:16.664082Z",
     "shell.execute_reply": "2025-04-01T15:25:16.663055Z"
    },
    "executionInfo": {
     "elapsed": 1347,
     "status": "ok",
     "timestamp": 1742798466748,
     "user": {
      "displayName": "Narasimha Murthy Panchangam",
      "userId": "15024520267351528624"
     },
     "user_tz": -330
    },
    "id": "7d29335d-0550-47cc-a59f-ac72fe2ea0e3",
    "papermill": {
     "duration": 1.449102,
     "end_time": "2025-04-01T15:25:16.665977",
     "exception": false,
     "start_time": "2025-04-01T15:25:15.216875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "poly_mod_degree = 8192\n",
    "coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 21, 40]\n",
    "# create TenSEALContext\n",
    "ctx_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "ctx_training.global_scale = 2 ** 21\n",
    "ctx_training.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69019420",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T15:25:16.677817Z",
     "iopub.status.busy": "2025-04-01T15:25:16.677369Z",
     "iopub.status.idle": "2025-04-01T15:25:16.681604Z",
     "shell.execute_reply": "2025-04-01T15:25:16.680452Z"
    },
    "executionInfo": {
     "elapsed": 27042,
     "status": "ok",
     "timestamp": 1742798845589,
     "user": {
      "displayName": "Narasimha Murthy Panchangam",
      "userId": "15024520267351528624"
     },
     "user_tz": -330
    },
    "id": "fca037ed-0491-4249-8032-e567ff666951",
    "outputId": "1cc5433b-df31-4bba-8614-9d9a4864e8ec",
    "papermill": {
     "duration": 0.011723,
     "end_time": "2025-04-01T15:25:16.683343",
     "exception": false,
     "start_time": "2025-04-01T15:25:16.671620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#t_start = time()\n",
    "#enc_x_train = ts.ckks_tensor(ctx_training, x_train[0:300])\n",
    "#enc_y_train = ts.ckks_tensor(ctx_training, y_train[0:300])\n",
    "#t_end = time()\n",
    "#print(f\"Encryption of the training_set took {int(t_end - t_start)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99c1f1b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T15:25:16.694348Z",
     "iopub.status.busy": "2025-04-01T15:25:16.694025Z",
     "iopub.status.idle": "2025-04-01T15:25:16.708550Z",
     "shell.execute_reply": "2025-04-01T15:25:16.707142Z"
    },
    "executionInfo": {
     "elapsed": 402,
     "status": "ok",
     "timestamp": 1742798869375,
     "user": {
      "displayName": "Narasimha Murthy Panchangam",
      "userId": "15024520267351528624"
     },
     "user_tz": -330
    },
    "id": "LocrA1zn57Ep",
    "papermill": {
     "duration": 0.022272,
     "end_time": "2025-04-01T15:25:16.710355",
     "exception": false,
     "start_time": "2025-04-01T15:25:16.688083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncryptedDL1layer() :\n",
    "  def __init__(self) -> None:\n",
    "      self.weight1=np.random.rand(11,3)*0.01\n",
    "      self.bias1=np.random.rand(3)*0.01\n",
    "      self.weight2=np.random.rand(3, 1)*0.01\n",
    "      self.bias2=np.random.rand(1)*0.01\n",
    "      self.dw1=0\n",
    "      self.db1=0\n",
    "      self.dw2=0\n",
    "      self.db2=0\n",
    "  def bootstrapping(enc,ctx_training) :\n",
    "    return ts.ckks_tensor(ctx_training,enc.decrypt())\n",
    "  def softplus(enc_x):\n",
    "    return enc_x.polyval([np.log(2),0.5,(1/8), 0,-(1/192)])\n",
    "  def softplus_derv(enc_x):\n",
    "    return enc_x.polyval([0.5,0.25,0,-(1/48)])\n",
    "  def forward(self,enc_x_train,ctx_training) :\n",
    "    z11=enc_x_train.mm(self.weight1)\n",
    "    z1=z11.add(self.bias1)\n",
    "    a1=EncryptedDL1layer.softplus(z1)\n",
    "    y=EncryptedDL1layer.bootstrapping(a1,ctx_training)\n",
    "    z21=y.mm(self.weight2)\n",
    "    z2=z21.add(self.bias2)\n",
    "    a2=EncryptedDL1layer.softplus(z2)\n",
    "    return a2,z2,a1,z1\n",
    "  def backward(self,a2,z2,a1,z1,enc_y_train,ctx_training) :\n",
    "    #calculating the output at the layer 2\n",
    "    error=a2-enc_y_train\n",
    "    der=EncryptedDL1layer.softplus_derv(z2)\n",
    "    #finding delta2\n",
    "    delta2=error.mul(der)\n",
    "    #using bootstrapping\n",
    "    delta2=EncryptedDL1layer.bootstrapping(delta2,ctx_training)\n",
    "    #finding delta1\n",
    "    del1=delta2.mm(self.weight2.transpose())\n",
    "    del1=EncryptedDL1layer.bootstrapping(del1,ctx_training)\n",
    "    #finding der1\n",
    "    der1=EncryptedDL1layer.softplus_derv(z1)\n",
    "    #using bootstrapping\n",
    "    der1=EncryptedDL1layer.bootstrapping(der1,ctx_training)\n",
    "    #finding delta1\n",
    "    delta1=del1.mul(der1)\n",
    "    #finding the gradients\n",
    "    #for weight2 and bias2\n",
    "    self.dw2=a1.transpose().mm(delta2)\n",
    "    self.db2=delta2.sum()\n",
    "    #for weight1 and bias1\n",
    "    self.dw1=enc_x_train.transpose().mm(delta1)\n",
    "    self.db1=delta1.sum()\n",
    "  def update_params(self):\n",
    "    self.weight2=self.weight2-0.01*self.dw2\n",
    "    self.bias2=self.bias2-0.01*self.db2\n",
    "    self.weight1=self.weight1-0.01*self.dw1\n",
    "    self.bias1=self.bias1-0.01*self.db1\n",
    "  def encrypt(self, context):\n",
    "    self.weight1 = ts.ckks_tensor(context, self.weight1)\n",
    "    self.bias1 = ts.ckks_tensor(context, self.bias1)\n",
    "    self.weight2 = ts.ckks_tensor(context, self.weight2)\n",
    "    self.bias2 = ts.ckks_tensor(context, self.bias2)\n",
    "  def decrypt(self):\n",
    "    self.weight1 = self.weight1.decrypt()\n",
    "    self.bias1 = self.bias1.decrypt()\n",
    "    self.weight2 = self.weight2.decrypt()\n",
    "    self.bias2 = self.bias2.decrypt()\n",
    "  def accuracy(self,x_test,y_test):\n",
    "    #self.decrypt()\n",
    "    w1 = torch.tensor(self.weight1)\n",
    "    b1 = torch.tensor(self.bias1)\n",
    "    out1 = torch.softplus(x_test.matmul(w1) + b1).reshape(-1, 1)\n",
    "    w2 = torch.tensor(self.weight2)\n",
    "    b2 = torch.tensor(self.bias2)\n",
    "    out2 = torch.softplus(out1.matmul(w2) + b2).reshape(-1, 1)\n",
    "    correct = torch.abs(y_test - out2) < 0.5\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69c4461c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T15:25:16.721665Z",
     "iopub.status.busy": "2025-04-01T15:25:16.721266Z",
     "iopub.status.idle": "2025-04-01T17:46:11.134560Z",
     "shell.execute_reply": "2025-04-01T17:46:11.133237Z"
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "error",
     "timestamp": 1742798872001,
     "user": {
      "displayName": "Narasimha Murthy Panchangam",
      "userId": "15024520267351528624"
     },
     "user_tz": -330
    },
    "id": "vj7f2Rt3BTsJ",
    "outputId": "8a0f6c19-8d47-4bb6-c90a-2509b6cf5d03",
    "papermill": {
     "duration": 8454.437169,
     "end_time": "2025-04-01T17:46:11.152494",
     "exception": false,
     "start_time": "2025-04-01T15:25:16.715325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  0\n",
      "Batch :  0.0\n",
      "Encryption of the training_set took 4 seconds\n",
      "Time taken for this batch :  68.64735102653503\n",
      "Batch :  1.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.44124865531921\n",
      "Batch :  2.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.00096225738525\n",
      "Batch :  3.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.15511131286621\n",
      "Batch :  4.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.54780316352844\n",
      "Batch :  5.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.38859629631042\n",
      "Batch :  6.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.2897355556488\n",
      "Batch :  7.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.52614665031433\n",
      "Batch :  8.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.90835785865784\n",
      "Batch :  9.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.1291196346283\n",
      "Batch :  10.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.77474522590637\n",
      "Batch :  11.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  63.974076986312866\n",
      "Batch :  12.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  63.850011587142944\n",
      "Loss at epoch  0 tensor(0.6700)\n",
      "Accuracy for the epoch  0 tensor(0.9333)\n",
      "Epoch :  1\n",
      "Batch :  0.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  63.95109844207764\n",
      "Batch :  1.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  63.84467840194702\n",
      "Batch :  2.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  63.73503494262695\n",
      "Batch :  3.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  63.66168928146362\n",
      "Batch :  4.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.12938857078552\n",
      "Batch :  5.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  63.82957911491394\n",
      "Batch :  6.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  63.73298454284668\n",
      "Batch :  7.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  63.829872369766235\n",
      "Batch :  8.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.0145161151886\n",
      "Batch :  9.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.48467421531677\n",
      "Batch :  10.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.39859557151794\n",
      "Batch :  11.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.78388047218323\n",
      "Batch :  12.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.3602774143219\n",
      "Loss at epoch  1 tensor(0.5633)\n",
      "Accuracy for the epoch  1 tensor(1.)\n",
      "Epoch :  2\n",
      "Batch :  0.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.50262188911438\n",
      "Batch :  1.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.70544457435608\n",
      "Batch :  2.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.58463978767395\n",
      "Batch :  3.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.10043978691101\n",
      "Batch :  4.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.10858511924744\n",
      "Batch :  5.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.24512243270874\n",
      "Batch :  6.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.11460947990417\n",
      "Batch :  7.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.94194650650024\n",
      "Batch :  8.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.62918543815613\n",
      "Batch :  9.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.77984952926636\n",
      "Batch :  10.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.70102620124817\n",
      "Batch :  11.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.47043299674988\n",
      "Batch :  12.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.07105875015259\n",
      "Loss at epoch  2 tensor(0.5128)\n",
      "Accuracy for the epoch  2 tensor(1.)\n",
      "Epoch :  3\n",
      "Batch :  0.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.39263820648193\n",
      "Batch :  1.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.9726414680481\n",
      "Batch :  2.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.91879725456238\n",
      "Batch :  3.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.0460569858551\n",
      "Batch :  4.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.00276732444763\n",
      "Batch :  5.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.07815027236938\n",
      "Batch :  6.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.46884632110596\n",
      "Batch :  7.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.36779069900513\n",
      "Batch :  8.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.08160543441772\n",
      "Batch :  9.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.32437539100647\n",
      "Batch :  10.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.29447603225708\n",
      "Batch :  11.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.28606581687927\n",
      "Batch :  12.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.38080787658691\n",
      "Loss at epoch  3 tensor(0.5005)\n",
      "Accuracy for the epoch  3 tensor(1.)\n",
      "Epoch :  4\n",
      "Batch :  0.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.30306816101074\n",
      "Batch :  1.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.71718168258667\n",
      "Batch :  2.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  63.89246702194214\n",
      "Batch :  3.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  62.85032391548157\n",
      "Batch :  4.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  63.05337309837341\n",
      "Batch :  5.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  63.16613698005676\n",
      "Batch :  6.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  63.01302933692932\n",
      "Batch :  7.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.55402660369873\n",
      "Batch :  8.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.28802633285522\n",
      "Batch :  9.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  66.89408135414124\n",
      "Batch :  10.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.63619947433472\n",
      "Batch :  11.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.6027991771698\n",
      "Batch :  12.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  66.52464628219604\n",
      "Loss at epoch  4 tensor(0.4980)\n",
      "Accuracy for the epoch  4 tensor(1.)\n",
      "Epoch :  5\n",
      "Batch :  0.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  67.20231199264526\n",
      "Batch :  1.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  66.36545300483704\n",
      "Batch :  2.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  67.83783531188965\n",
      "Batch :  3.0\n",
      "Encryption of the training_set took 4 seconds\n",
      "Time taken for this batch :  66.87142729759216\n",
      "Batch :  4.0\n",
      "Encryption of the training_set took 4 seconds\n",
      "Time taken for this batch :  67.37997722625732\n",
      "Batch :  5.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.25118064880371\n",
      "Batch :  6.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.40485095977783\n",
      "Batch :  7.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.59597611427307\n",
      "Batch :  8.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.61101698875427\n",
      "Batch :  9.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.40923070907593\n",
      "Batch :  10.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.77815318107605\n",
      "Batch :  11.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.73272943496704\n",
      "Batch :  12.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.50328850746155\n",
      "Loss at epoch  5 tensor(0.4976)\n",
      "Accuracy for the epoch  5 tensor(1.)\n",
      "Epoch :  6\n",
      "Batch :  0.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.69742560386658\n",
      "Batch :  1.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.4158022403717\n",
      "Batch :  2.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.98832654953003\n",
      "Batch :  3.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.83597898483276\n",
      "Batch :  4.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.88005304336548\n",
      "Batch :  5.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.05447244644165\n",
      "Batch :  6.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.08313202857971\n",
      "Batch :  7.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.64238739013672\n",
      "Batch :  8.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.32690048217773\n",
      "Batch :  9.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.47026562690735\n",
      "Batch :  10.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.57119584083557\n",
      "Batch :  11.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.62917256355286\n",
      "Batch :  12.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.9224443435669\n",
      "Loss at epoch  6 tensor(0.4975)\n",
      "Accuracy for the epoch  6 tensor(1.)\n",
      "Epoch :  7\n",
      "Batch :  0.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.78009295463562\n",
      "Batch :  1.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.78857588768005\n",
      "Batch :  2.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.23647809028625\n",
      "Batch :  3.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.87889099121094\n",
      "Batch :  4.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.44928312301636\n",
      "Batch :  5.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.47802877426147\n",
      "Batch :  6.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.92055773735046\n",
      "Batch :  7.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.68379735946655\n",
      "Batch :  8.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.53901791572571\n",
      "Batch :  9.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.9463484287262\n",
      "Batch :  10.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.04087829589844\n",
      "Batch :  11.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.97572708129883\n",
      "Batch :  12.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.61026191711426\n",
      "Loss at epoch  7 tensor(0.4979)\n",
      "Accuracy for the epoch  7 tensor(1.)\n",
      "Epoch :  8\n",
      "Batch :  0.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.15697646141052\n",
      "Batch :  1.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.13001441955566\n",
      "Batch :  2.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.92450714111328\n",
      "Batch :  3.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.50158762931824\n",
      "Batch :  4.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.66910314559937\n",
      "Batch :  5.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.8468828201294\n",
      "Batch :  6.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.88053512573242\n",
      "Batch :  7.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.750807762146\n",
      "Batch :  8.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.9426953792572\n",
      "Batch :  9.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.73758316040039\n",
      "Batch :  10.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.86931824684143\n",
      "Batch :  11.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.15411376953125\n",
      "Batch :  12.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.33910989761353\n",
      "Loss at epoch  8 tensor(0.4973)\n",
      "Accuracy for the epoch  8 tensor(1.)\n",
      "Epoch :  9\n",
      "Batch :  0.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.72664880752563\n",
      "Batch :  1.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.01735782623291\n",
      "Batch :  2.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.07532238960266\n",
      "Batch :  3.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  64.80182695388794\n",
      "Batch :  4.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.7972002029419\n",
      "Batch :  5.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.93740677833557\n",
      "Batch :  6.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.82822275161743\n",
      "Batch :  7.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.53759694099426\n",
      "Batch :  8.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.56998920440674\n",
      "Batch :  9.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.6382851600647\n",
      "Batch :  10.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  66.34891867637634\n",
      "Batch :  11.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  66.47932553291321\n",
      "Batch :  12.0\n",
      "Encryption of the training_set took 3 seconds\n",
      "Time taken for this batch :  65.27358269691467\n",
      "Loss at epoch  9 tensor(0.4969)\n",
      "Accuracy for the epoch  9 tensor(1.)\n",
      "\n",
      "Average time per epoch: 65 seconds\n",
      "Final weight1  [[-0.009382621854177433, 0.027505863626645862, -0.031363278797688195], [-0.034715554387972414, 0.036097689605478475, -0.03551078427369741], [0.0024576119894447576, -0.0210394507163827, 0.020351346746595188], [0.023648741784185613, -0.008806587162136644, -0.019417608987063677], [0.0032957056320650387, 0.011781240610582252, -0.022402752442626163], [0.011629033890650644, 0.005292810294859389, -0.020095864364171316], [-0.014223042450615966, -0.002382827947055972, 0.000917830253201592], [-0.0029150446617876007, 0.003243193661441041, 0.005705461455633144], [-0.006955071477910038, -0.015313492712023225, 0.03168446475308119], [-0.030840583285932623, 0.02540383504614405, -0.01669754164970241], [-0.8304667339715675, -1.0541390683085865, -0.7312520599019778]]\n",
      "Final bias 1 [0.0009818497722285122, 0.015566553299042975, -0.04960241701212375]\n",
      "Final weight 2 [[-0.5322184663532944], [-0.8218817651077127], [-0.4004553502460346]]\n",
      "Final bias 2 [0.9721120007864964]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "eelr = EncryptedDL1layer()\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"Epoch : \",epoch)\n",
    "    times = []\n",
    "    t_start = time()\n",
    "    for i in range(0,780,60):\n",
    "        print(\"Batch : \",i/60)\n",
    "        t_start = time()\n",
    "        enc_x_train = ts.ckks_tensor(ctx_training, x_train[i:i+60])\n",
    "        enc_y_train = ts.ckks_tensor(ctx_training, y_train[i:i+60])\n",
    "        t_end = time()\n",
    "        print(f\"Encryption of the training_set took {int(t_end - t_start)} seconds\")\n",
    "        eelr.encrypt(ctx_training)\n",
    "        a2,z2,a1,z1 = eelr.forward(enc_x_train,ctx_training)\n",
    "        eelr.backward(a2,z2,a1,z1,enc_y_train,ctx_training)\n",
    "        eelr.update_params()\n",
    "        t_end = time()\n",
    "        eelr.decrypt()\n",
    "        print(\"Time taken for this batch : \",t_end - t_start)\n",
    "    times.append(t_end - t_start)\n",
    "    data=torch.tensor(a2.decrypt().tolist())\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "    loss = loss_fn(data, y_train[i:i+60])\n",
    "    print(\"Loss at epoch \",epoch,loss.data)\n",
    "    out=torch.tensor(enc_y_train.sub(a2).decrypt().tolist())\n",
    "    correct=torch.abs(out)<0.5\n",
    "    print(\"Accuracy for the epoch \",epoch,correct.float().mean())\n",
    "print(f\"\\nAverage time per epoch: {int(sum(times) / len(times))} seconds\")\n",
    "print(\"Final weight1 \",eelr.weight1.tolist())\n",
    "print(\"Final bias 1\",eelr.bias1.tolist())\n",
    "print(\"Final weight 2\",eelr.weight2.tolist())\n",
    "print(\"Final bias 2\",eelr.bias2.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9e9d06b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T17:46:11.188758Z",
     "iopub.status.busy": "2025-04-01T17:46:11.188339Z",
     "iopub.status.idle": "2025-04-01T17:46:25.899752Z",
     "shell.execute_reply": "2025-04-01T17:46:25.898529Z"
    },
    "executionInfo": {
     "elapsed": 92271,
     "status": "ok",
     "timestamp": 1742745772755,
     "user": {
      "displayName": "Narasimha Murthy",
      "userId": "00427524539684510099"
     },
     "user_tz": -330
    },
    "id": "KLgUVLDRjFUR",
    "outputId": "0516727f-29d4-430d-df09-8d40fa237b83",
    "papermill": {
     "duration": 14.731963,
     "end_time": "2025-04-01T17:46:25.901738",
     "exception": false,
     "start_time": "2025-04-01T17:46:11.169775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#eelr.encrypt(ctx_training)\n",
    "j,k,l,r=eelr.forward(enc_x_train,ctx_training)\n",
    "#enc_y_train.sub(j).decrypt().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c1d8d3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T17:46:25.938191Z",
     "iopub.status.busy": "2025-04-01T17:46:25.937859Z",
     "iopub.status.idle": "2025-04-01T17:46:26.102623Z",
     "shell.execute_reply": "2025-04-01T17:46:26.101614Z"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1742746346136,
     "user": {
      "displayName": "Narasimha Murthy",
      "userId": "00427524539684510099"
     },
     "user_tz": -330
    },
    "id": "_UaJ3vhlvLCX",
    "outputId": "8854fc07-8857-4b2b-b1b1-07b7a048fa53",
    "papermill": {
     "duration": 0.184975,
     "end_time": "2025-04-01T17:46:26.104789",
     "exception": false,
     "start_time": "2025-04-01T17:46:25.919814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "out=torch.tensor(enc_y_train.sub(j).decrypt().tolist())\n",
    "correct=torch.abs(out)<0.5\n",
    "print(correct.float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "515554e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T17:46:26.141984Z",
     "iopub.status.busy": "2025-04-01T17:46:26.141637Z",
     "iopub.status.idle": "2025-04-01T17:46:49.816826Z",
     "shell.execute_reply": "2025-04-01T17:46:49.815037Z"
    },
    "id": "WiNUecEKxti0",
    "papermill": {
     "duration": 23.695805,
     "end_time": "2025-04-01T17:46:49.818862",
     "exception": false,
     "start_time": "2025-04-01T17:46:26.123057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc_x_test = ts.ckks_tensor(ctx_training, x_test)\n",
    "enc_y_test = ts.ckks_tensor(ctx_training, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8764bf77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T17:46:49.857133Z",
     "iopub.status.busy": "2025-04-01T17:46:49.856750Z",
     "iopub.status.idle": "2025-04-01T17:48:24.646859Z",
     "shell.execute_reply": "2025-04-01T17:48:24.645439Z"
    },
    "papermill": {
     "duration": 94.811488,
     "end_time": "2025-04-01T17:48:24.648839",
     "exception": false,
     "start_time": "2025-04-01T17:46:49.837351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "m,n,j,k=eelr.forward(enc_x_test,ctx_training)\n",
    "out=torch.tensor(enc_y_test.sub(m).decrypt().tolist())\n",
    "correct=torch.abs(out)<0.5\n",
    "print(correct.float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1652ed8",
   "metadata": {
    "papermill": {
     "duration": 0.017478,
     "end_time": "2025-04-01T17:48:24.684256",
     "exception": false,
     "start_time": "2025-04-01T17:48:24.666778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6961199,
     "sourceId": 11156928,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7023869,
     "sourceId": 11242015,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8612.107099,
   "end_time": "2025-04-01T17:48:29.420645",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-01T15:24:57.313546",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
